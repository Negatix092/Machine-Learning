{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "https://colab.research.google.com/drive/1yHwUpFi4nCX-Yr3WBFMRfrW6wVQHqUud?usp=sharing "
      ],
      "metadata": {
        "id": "8Z_MHoGaJjmJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "from sklearn import datasets, linear_model\n",
        "  \n",
        "# reading the csv file\n",
        "df = pd.read_csv(\"sample_data/StudentsPerformance.csv\")\n",
        "  \n",
        "# updating the column value/data\n",
        "\n",
        "#gender\n",
        "df['gender'] = df['gender'].replace({'female': '1'})\n",
        "df['gender'] = df['gender'].replace({'male': '2'})\n",
        "\n",
        "#race/ethnicity\n",
        "df['race/ethnicity'] = df['race/ethnicity'].replace({'group A':'1'})\n",
        "df['race/ethnicity'] = df['race/ethnicity'].replace({'group B':'2'})\n",
        "df['race/ethnicity'] = df['race/ethnicity'].replace({'group C':'3'})\n",
        "df['race/ethnicity'] = df['race/ethnicity'].replace({'group D':'4'})\n",
        "df['race/ethnicity'] = df['race/ethnicity'].replace({'group E':'5'})\n",
        "\n",
        "#parental level of education\n",
        "df['parental level of education'] = df['parental level of education'].replace({'some high school':'1'})\n",
        "df['parental level of education'] = df['parental level of education'].replace({'high school':'2'})\n",
        "df['parental level of education'] = df['parental level of education'].replace({\"bachelor's degree\":'3'})\n",
        "df['parental level of education'] = df['parental level of education'].replace({'some college':'4'})\n",
        "df['parental level of education'] = df['parental level of education'].replace({\"master's degree\":'5'})\n",
        "df['parental level of education'] = df['parental level of education'].replace({\"associate's degree\":'6'})\n",
        "\n",
        "#lunch\n",
        "df['lunch'] = df['lunch'].replace({'standard':'1'})\n",
        "df['lunch'] = df['lunch'].replace({'free/reduced':'2'})\n",
        "\n",
        "\n",
        "#test preparation course\n",
        "df['test preparation course'] = df['test preparation course'].replace({'none':'1'})\n",
        "df['test preparation course'] = df['test preparation course'].replace({'completed':'2'})\n",
        "  \n",
        "df.head()"
      ],
      "metadata": {
        "id": "N_GBpJRZIHfX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "3aa250a9-caef-4f5c-92c6-06e3b2f25bf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  gender race/ethnicity parental level of education lunch  \\\n",
              "0      1              2                           3     1   \n",
              "1      1              3                           4     1   \n",
              "2      1              2                           5     1   \n",
              "3      2              1                           6     2   \n",
              "4      2              3                           4     1   \n",
              "\n",
              "  test preparation course  math score  reading score  writing score  \n",
              "0                       1          72             72             74  \n",
              "1                       2          69             90             88  \n",
              "2                       1          90             95             93  \n",
              "3                       1          47             57             44  \n",
              "4                       1          76             78             75  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b44df261-2f9a-420d-aa10-af7b5ebf0ed4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>race/ethnicity</th>\n",
              "      <th>parental level of education</th>\n",
              "      <th>lunch</th>\n",
              "      <th>test preparation course</th>\n",
              "      <th>math score</th>\n",
              "      <th>reading score</th>\n",
              "      <th>writing score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>72</td>\n",
              "      <td>72</td>\n",
              "      <td>74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>69</td>\n",
              "      <td>90</td>\n",
              "      <td>88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>90</td>\n",
              "      <td>95</td>\n",
              "      <td>93</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>47</td>\n",
              "      <td>57</td>\n",
              "      <td>44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>76</td>\n",
              "      <td>78</td>\n",
              "      <td>75</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b44df261-2f9a-420d-aa10-af7b5ebf0ed4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b44df261-2f9a-420d-aa10-af7b5ebf0ed4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b44df261-2f9a-420d-aa10-af7b5ebf0ed4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Codigo Alex Mate"
      ],
      "metadata": {
        "id": "mEwcubwI1lg5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np #matlab de python\n",
        "from sklearn import datasets, linear_model\n",
        "from sklearn.metrics import mean_squared_error, r2_score #MSE función de costo\n",
        "\n",
        "#here we just organize our dataset in order to only have inputs and outputs\n",
        "\n",
        "#outputs\n",
        "output_Math = 'math score'\n",
        "output_Reading = 'reading score'\n",
        "output_Writing = 'writing score'\n",
        "\n",
        "#inputs\n",
        "all_X = df.columns.tolist()\n",
        "all_X.remove(output_Math)\n",
        "all_X.remove(output_Reading)\n",
        "all_X.remove(output_Writing)"
      ],
      "metadata": {
        "id": "eKzJkke9co6b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#here we can visualize which ones will be our inputs, as wanted\n",
        "all_X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OpBsNYQ1DNf5",
        "outputId": "533d7c3b-878d-44d4-f309-04b3b47af6f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['gender',\n",
              " 'race/ethnicity',\n",
              " 'parental level of education',\n",
              " 'lunch',\n",
              " 'test preparation course']"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#we need to manage the data of our inputs\n",
        "#all_X_values = df[all_X].values\n",
        "\n",
        "# Use only one feature, gender. \n",
        "#all_X_values = df['gender'].values \n",
        "#all_X_values = np.reshape(all_X_values, (-1, 1))#column vector\n",
        "\n",
        "# Use only one feature, race/ethnicity. \n",
        "#all_X_values = df['race/ethnicity'].values \n",
        "#all_X_values = np.reshape(all_X_values, (-1, 1))#column vector\n",
        "\n",
        "# Use only one feature, parental level of education. \n",
        "all_X_values = df['parental level of education'].values \n",
        "all_X_values = np.reshape(all_X_values, (-1, 1))#column vector\n",
        "\n",
        "# Use only one feature, lunch. \n",
        "#all_X_values = df['lunch'].values \n",
        "#all_X_values = np.reshape(all_X_values, (-1, 1))#column vector\n",
        "\n",
        "# Use only one feature, test preparation course. \n",
        "#all_X_values = df['test preparation course'].values \n",
        "#all_X_values = np.reshape(all_X_values, (-1, 1))#column vector\n",
        "\n",
        "\n",
        "#we need to manage the data of our outputs (for my case is the math test only)\n",
        "math_score_Y = df[output_Math].values\n",
        "\n",
        "#split the data into training/testing sets\n",
        "all_X_values_train = all_X_values[:-200] \n",
        "all_X_values_test = all_X_values[-200:] #last 200 for test\n",
        "\n",
        "#split the targets into training/testing sets\n",
        "math_score_Y_train = math_score_Y[:-200]\n",
        "math_score_Y_test = math_score_Y[-200:] \n",
        "\n",
        "#As accorded, since we are dealing with 1000 rows of data, we are going to use 800 for training our model and 200 for testing it"
      ],
      "metadata": {
        "id": "LDvN2ppBENlE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create linear regression object\n",
        "regr = linear_model.LinearRegression()\n",
        "\n",
        "# normalize data to have zero mean and std one (feature scaling)\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(all_X_values_train)# scaler fit is just for training dataset \n",
        "all_X_values_train_normalized = scaler.transform(all_X_values_train) #normalize training set\n",
        "\n",
        "# Train the model using the training sets\n",
        "regr.fit(all_X_values_train_normalized, math_score_Y_train) # 1. REPRESENTAR hypothesis, 2. EVALUAR MSE Error Cuadratico Medio 3. OPTIMIZAR (Gradient Descent)\n",
        "\n",
        "# Make predictions using the testing set\n",
        "all_X_values_test_normalized = scaler.transform(all_X_values_test) #normalize test set \n",
        "math_score_Y_pred = regr.predict(all_X_values_test_normalized)\n",
        "\n",
        "# The coefficients theta_0 (inter.), theta_1 (pendiente)\n",
        "print(\"Coefficients: \\n\", \"theta_values = \", regr.coef_, \" theta_0  = \", regr.intercept_)\n",
        "#print(\"Coefficients: \\n\", regr.coef_, regr.intercept_)\n",
        "# The mean squared error\n",
        "print(\"Mean squared error (MSE Cost): %.2f\" % mean_squared_error(math_score_Y_test, math_score_Y_pred))\n",
        "# The coefficient of determination: 1 is perfect prediction, varía entre 0 y 1\n",
        "print(\"Coefficient of determination: %.2f\" % r2_score(math_score_Y_test, math_score_Y_pred))\n",
        "\n",
        "#Since we are dealing with multiple variables, plotting the result is not a viable option\n",
        "\n",
        "# When we deal with only one input, we can get the plot outputs\n",
        "plt.scatter(all_X_values_test_normalized, math_score_Y_test, color=\"black\")\n",
        "plt.plot(all_X_values_test_normalized, math_score_Y_pred, color=\"blue\", linewidth=3)\n",
        "\n",
        "plt.xticks(())\n",
        "plt.yticks(())\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475
        },
        "id": "ZGHG_Y9jA496",
        "outputId": "d40e918b-6176-492d-9e4c-8614b4d844a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coefficients: \n",
            " theta_values =  [1.83617143]  theta_0  =  65.98625\n",
            "Mean squared error (MSE Cost): 237.86\n",
            "Coefficient of determination: 0.02\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_X_values_train_normalized[0:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfndBlKkHqR7",
        "outputId": "c75422f5-b822-4921-a1fe-41f89699dfaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.  , 0.25, 0.4 , 0.  , 0.  ],\n",
              "       [0.  , 0.5 , 0.6 , 0.  , 1.  ],\n",
              "       [0.  , 0.25, 0.8 , 0.  , 0.  ],\n",
              "       [1.  , 0.  , 1.  , 1.  , 0.  ],\n",
              "       [1.  , 0.5 , 0.6 , 0.  , 0.  ],\n",
              "       [0.  , 0.25, 1.  , 0.  , 0.  ],\n",
              "       [0.  , 0.25, 0.6 , 0.  , 1.  ],\n",
              "       [1.  , 0.25, 0.6 , 1.  , 0.  ],\n",
              "       [1.  , 0.75, 0.2 , 1.  , 1.  ],\n",
              "       [0.  , 0.25, 0.2 , 1.  , 0.  ]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "import numpy as np # numpy~Matlab\n",
        "lambda_value = 0.001 #hyperparameter \n",
        "\n",
        "#classifier = LogisticRegression(penalty='none').fit(all_X_values_train_normalized, math_score_Y_train) #penalty='none' -> sin regularización , lambda =0, representación+eval+opt\n",
        "classifier = LogisticRegression(penalty='l2', C=1/lambda_value, max_iter=10000).fit(all_X_values_train_normalized, math_score_Y_train) #spenalty='l2' -> con regularización \n",
        "\n",
        "accuracy = classifier.score(all_X_values_train_normalized, math_score_Y_train) #exactitud en el conjunto de entrenamiento\n",
        "print(accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RY5yqMLIu3v",
        "outputId": "d461a647-3062-407c-b8c7-a0b3e8eae523"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.04625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Codigo Emi Writing"
      ],
      "metadata": {
        "id": "4S__SUw91nuo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#we need to manage the data of our inputs\n",
        "all_X_values = df[all_X].values\n",
        "\n",
        "#we need to manage the data of our outputs (for my case is the math test only)\n",
        "writing_score_Y = df[output_Writing].values\n",
        "\n",
        "#split the data into training/testing sets\n",
        "all_X_values_train = all_X_values[:-200] \n",
        "all_X_values_test = all_X_values[-200:] #last 200 for test\n",
        "\n",
        "#split the targets into training/testing sets\n",
        "writing_score_Y_train = writing_score_Y[:-200]\n",
        "writing_score_Y_test = writing_score_Y[-200:] \n",
        "\n",
        "#As accorded, since we are dealing with 1000 rows of data, we are going to use 800 for training our model and 200 for testing it"
      ],
      "metadata": {
        "id": "4XlwgFOy6uTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create linear regression object\n",
        "regr = linear_model.LinearRegression()\n",
        "\n",
        "# normalize data to have zero mean and std one (feature scaling)\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(all_X_values_train)# scaler fit is just for training dataset \n",
        "all_X_values_train_normalized = scaler.transform(all_X_values_train) #normalize training set\n",
        "\n",
        "# Train the model using the training sets\n",
        "regr.fit(all_X_values_train_normalized, writing_score_Y_train) # 1. REPRESENTAR hypothesis, 2. EVALUAR MSE Error Cuadratico Medio 3. OPTIMIZAR (Gradient Descent)\n",
        "\n",
        "# Make predictions using the testing set\n",
        "all_X_values_test_normalized = scaler.transform(all_X_values_test) #normalize test set \n",
        "writing_score_Y_pred = regr.predict(all_X_values_test_normalized)\n",
        "\n",
        "# The coefficients theta_0 (inter.), theta_1 (pendiente)\n",
        "print(\"Coefficients: \\n\", \"theta_values = \", regr.coef_, \" theta_0  = \", regr.intercept_)\n",
        "#print(\"Coefficients: \\n\", regr.coef_, regr.intercept_)\n",
        "# The mean squared error\n",
        "print(\"Mean squared error (MSE Cost): %.2f\" % mean_squared_error(writing_score_Y_test, writing_score_Y_pred))\n",
        "# The coefficient of determination: 1 is perfect prediction, varía entre 0 y 1\n",
        "print(\"Coefficient of determination: %.2f\" % r2_score(writing_score_Y_test, writing_score_Y_pred))\n",
        "\n",
        "#Since we are dealing with multiple variables, plotting the result is not a viable option"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKjaEwFB7uxd",
        "outputId": "0037a978-a3cc-46a4-bb4c-f2a198e78190"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coefficients: \n",
            " theta_values =  [-4.64148619  1.82684455  2.20106493 -3.63872622  5.07625574]  theta_0  =  67.88375\n",
            "Mean squared error (MSE Cost): 178.82\n",
            "Coefficient of determination: 0.26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "import numpy as np # numpy~Matlab\n",
        "lambda_value = 0.001 #hyperparameter \n",
        "\n",
        "#classifier = LogisticRegression(penalty='none').fit(all_X_values_train_normalized, math_score_Y_train) #penalty='none' -> sin regularización , lambda =0, representación+eval+opt\n",
        "classifier = LogisticRegression(penalty='l2', C=1/lambda_value, max_iter=10000).fit(all_X_values_train_normalized, writing_score_Y_train) #spenalty='l2' -> con regularización \n",
        "\n",
        "accuracy = classifier.score(all_X_values_train_normalized, writing_score_Y_train) #exactitud en el conjunto de entrenamiento\n",
        "print(accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZpM-xVOAgNi",
        "outputId": "f9b15a41-211b-45bc-96d3-5ead0c239b54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Codigo Juan READING"
      ],
      "metadata": {
        "id": "5QsTqJgN1pEB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#we need to manage the data of our inputs\n",
        "all_X_values = df[all_X].values\n",
        "\n",
        "#we need to manage the data of our outputs (for my case is the math test only)\n",
        "reading_score_Y = df[output_Reading].values\n",
        "\n",
        "#split the data into training/testing sets\n",
        "all_X_values_train = all_X_values[:-200] \n",
        "all_X_values_test = all_X_values[-200:] #last 200 for test\n",
        "\n",
        "#split the targets into training/testing sets\n",
        "reading_score_Y_train = reading_score_Y[:-200]\n",
        "reading_score_Y_test = reading_score_Y[-200:] \n",
        "\n",
        "# Create linear regression object\n",
        "from sklearn.linear_model import Lasso\n",
        "\n",
        "#regr_reading=linear_model.LinearRegression()\n",
        "lambda_value = 10000 #hyperparameter \n",
        "regr_reading = Lasso(alpha=1)\n",
        "\n",
        "# normalize data to have zero mean and std one (feature scaling)\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(all_X_values_train)# scaler fit is just for training dataset \n",
        "all_X_values_train_normalized = scaler.transform(all_X_values_train) #normalize training set\n",
        "\n",
        "# Train the model using the training sets\n",
        "regr_reading.fit(all_X_values_train_normalized, math_score_Y_train) # 1. REPRESENTAR hypothesis, 2. EVALUAR MSE Error Cuadratico Medio 3. OPTIMIZAR (Gradient Descent)\n",
        "\n",
        "# Make predictions using the testing set\n",
        "all_X_values_test_normalized = scaler.transform(all_X_values_test) #normalize test set \n",
        "reading_score_Y_pred = regr_reading.predict(all_X_values_test_normalized)\n",
        "\n",
        "# The coefficients theta_0 (inter.), theta_1 (pendiente)\n",
        "print(\"Coefficients: \\n\", \"theta_values = \", regr_reading.coef_, \" theta_0  = \", regr_reading.intercept_)\n",
        "#print(\"Coefficients: \\n\", regr.coef_, regr.intercept_)\n",
        "# The mean squared error\n",
        "print(\"Mean squared error (MSE Cost): %.2f\" % mean_squared_error(reading_score_Y_test, reading_score_Y_pred))\n",
        "# The coefficient of determination: 1 is perfect prediction, varía entre 0 y 1\n",
        "print(\"Coefficient of determination: %.2f\" % r2_score(reading_score_Y_test, reading_score_Y_pred))"
      ],
      "metadata": {
        "id": "K0H-e7ee1rAY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a91dfeb-2311-453d-9fbe-aab758508a41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coefficients: \n",
            " theta_values =  [ 1.38473479  1.74804259  0.79924041 -4.00890501  1.99582076]  theta_0  =  65.98625\n",
            "Mean squared error (MSE Cost): 218.51\n",
            "Coefficient of determination: 0.03\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c4Xre8_AP2uG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}